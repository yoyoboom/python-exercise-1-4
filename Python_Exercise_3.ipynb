{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Exercise 3 - Yuki Yim",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yoyoboom/python-exercise-1-4/blob/master/Python_Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5hHCnwbMCux",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import pandas\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LassoLarsCV\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgiO3OPyMHVH",
        "colab_type": "code",
        "outputId": "d3099a2d-7822-43d1-a4bf-519e313572a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "alldata = pd.read_csv(open('drive/My Drive/finalmaster-ratios.csv'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYFvyvl7NBP4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "allvariablenames = list(alldata.columns.values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAUrpUekRDVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "listofallpredictors = allvariablenames[8:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtuDayxJNcDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load predictors into dataframe\n",
        "predictors = alldata[listofallpredictors]  \n",
        "\n",
        "#load target into dataframe\n",
        "target = alldata['# Purchases'] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RLijLPcNieQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split data into train and test sets, with 30% retained for test\n",
        "\n",
        "pred_train, pred_test, tar_train, tar_test = train_test_split(predictors, target, test_size=.3, random_state=123) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXGqzydDOZ2m",
        "colab_type": "code",
        "outputId": "d0570787-dd96-4566-8b60-cde741336879",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = LassoLarsCV(cv=10, precompute = False)\n",
        "lasso = model.fit(pred_train,tar_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.496e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=1.098e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=7.329e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.322e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=6.051e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 6.664e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=5.739e-01, previous alpha=5.739e-01, with an active set of 14 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=4.100e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.867e-01, with an active set of 27 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 44 iterations, i.e. alpha=2.050e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=2.013e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 46 iterations, alpha=1.986e-01, previous alpha=1.960e-01, with an active set of 37 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.365e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.008e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.144e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.642e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.053e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.644e-01, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.626e-01, previous alpha=5.354e-01, with an active set of 13 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.439e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.037e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.799e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 15 iterations, alpha=7.201e-01, previous alpha=7.200e-01, with an active set of 12 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=4.546e-02, with an active set of 90 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=4.539e-02, with an active set of 91 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 116 iterations, alpha=3.652e-02, previous alpha=3.599e-02, with an active set of 99 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.572e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.132e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.640e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.942e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=3.863e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=3.560e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=1.932e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=1.737e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 64 iterations, alpha=1.702e-01, previous alpha=1.687e-01, with an active set of 45 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.644e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.178e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=9.316e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.155e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.203e-01, previous alpha=3.135e-01, with an active set of 25 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.100e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.523e-02, with an active set of 60 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.523e-02, with an active set of 60 regressors, and the smallest cholesky pivot element being 6.495e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 68 iterations, alpha=6.435e-02, previous alpha=6.382e-02, with an active set of 61 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.147e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.014e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=8.010e-01, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=5.693e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.099e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.948e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 32 iterations, alpha=3.137e-01, previous alpha=3.116e-01, with an active set of 27 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=5.644e-01, with an active set of 11 regressors, and the smallest cholesky pivot element being 9.064e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=2.822e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 9.125e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 37 iterations, alpha=2.062e-01, previous alpha=1.984e-01, with an active set of 34 regressors.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.372e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=9.825e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=6.732e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 6.989e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=5.285e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 7.300e-08. Reduce max_iter or increase eps parameters.\n",
            "  ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 16 iterations, alpha=5.186e-01, previous alpha=5.185e-01, with an active set of 15 regressors.\n",
            "  ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIYr_uJ1PqCc",
        "colab_type": "code",
        "outputId": "c7ee0910-0cf2-469e-b8b7-cbc0ff88c991",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "#build coefficent chart\n",
        "\n",
        "predictors_model=pd.DataFrame(listofallpredictors)\n",
        "predictors_model.columns = ['label']\n",
        "predictors_model['coeff'] = model.coef_\n",
        "\n",
        "for index, row in predictors_model.iterrows():\n",
        "    if row['coeff'] > 0:\n",
        "        print(row.values)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['B01001014' 0.8558761066941788]\n",
            "['B01001036' 2.5053482381631653]\n",
            "['B01001037' 0.8892493223320962]\n",
            "['B01001038' 1.5316387928880384]\n",
            "['B02001005' 0.41252295298457853]\n",
            "['B13014026' 0.48004105312075906]\n",
            "['B13014027' 0.6978957445987839]\n",
            "['B13016001' 875149895.329212]\n",
            "['B19001017' 1.4834348068681533]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hspyEzq4P8of",
        "colab_type": "text"
      },
      "source": [
        "## Question 1\n",
        "In your own words, explain what the above lines of code are doing. Why am I doing it? Explain each line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGJWv14mTkF9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a new table called 'predictors_model' as the dataframe. Loading all predictors name from listofallpredictors.\n",
        "# name the column of predictors_model into 'label'.\n",
        "# add new column called 'coeff'and add all coefficients from model.\n",
        "# loop through predictor_model table\n",
        "# coefficient with name larger than 0.\n",
        "# print out the coefficients"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rwrF474WNrd",
        "colab_type": "text"
      },
      "source": [
        "# Question 2\n",
        "Interpret each variable intuitively. What Census variables most predict sales? What does that mean, practically? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rup6EUH_VMOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In areas where there are more males aged 40-44, we sell more Bobo Bars.\n",
        "# In areas where there are more females aged 30-34, we sell more Bobo Bars.\n",
        "# In areas where there are more females aged 35-39, we sell more Bobo Bars.\n",
        "# In areas where there are more females aged 40-44, we sell more Bobo Bars.\n",
        "# In areas where there are more Asians Alone, we sell more Bobo Bars.\n",
        "# In areas where there are more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Bachelor's degree, we sell more Bobo Bars.\n",
        "# In areas where there are more Women 15 to 50 Years Who Had a Birth in the Past 12 Months with Graduate or professional degree, we sell more Bobo Bars.\n",
        "# In areas where there are more Women 15 to 50 Years Who Had a Birth in the Past 12 Months, we sell more Bobo Bars.\n",
        "# In areas where there are more household with income $200,000 or more, we sell more Bobo Bars."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTo_bNtEYpJn",
        "colab_type": "text"
      },
      "source": [
        "# Question 3\n",
        "If I had to report only two census variables to my boss that most steeply predicted sales, what would those be?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImimaCg6YvOr",
        "colab_type": "code",
        "outputId": "53502aee-cac7-4b1c-ac8a-d44448d5c3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "train_error = mean_squared_error(tar_train, model.predict(pred_train))\n",
        "print ('training data MSE')\n",
        "print(train_error)\n",
        "\n",
        "train_error = mean_squared_error(tar_test, model.predict(pred_test))\n",
        "print ('testing data MSE')\n",
        "print(train_error)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data MSE\n",
            "22025.491066757\n",
            "testing data MSE\n",
            "41549.54803776253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOGK-NdUezaB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# if i had to report only 2 census variables to my boss that most steeply predicted sales, they will be women from 15 to 50who had birth in the past 12 months and females aged 30 to 34 years."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtdk5HnyZdco",
        "colab_type": "text"
      },
      "source": [
        "# Question 4\n",
        "Are the training and text set mean squared errors similar? What does that mean practically? Think back to your stats class, or Google it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xO0qOGXKZlYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training and test data set mean squared errors are NOT similar.\n",
        "# training data set has a higher match than the test data set.\n",
        "# training data has less value and it fits better."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xsFDZ2naxe0",
        "colab_type": "text"
      },
      "source": [
        "# Question 5\n",
        "If your boss asked, \"How well does Census data, overall, predict sales?\" What would you say? Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6RAVF71a2Y2",
        "colab_type": "code",
        "outputId": "b944580d-f736-43f6-c1ea-2dc4121a8a3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "#r squared\n",
        "rsquared_train=model.score(pred_train,tar_train)\n",
        "print ('training data R-square')\n",
        "print(rsquared_train)\n",
        "\n",
        "rsquared_test=model.score(pred_test,tar_test)\n",
        "print ('testing data R-square')\n",
        "print(rsquared_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training data R-square\n",
            "0.2400221219784492\n",
            "testing data R-square\n",
            "0.1758628512005107\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0dNLA1kbLSy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Census data overall cannot predict sales well. Because both training and testing data have large MSE values and small r-square values.\n",
        "# training data set has a better regression model due to the larger r-square value."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylV6BkxHbmU0",
        "colab_type": "text"
      },
      "source": [
        "# Question 6\n",
        "What is our baseline sales number? What does that mean, practically? Think back to what y-intercepts mean in regression models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVVFQ9kOcSG2",
        "colab_type": "code",
        "outputId": "45d9029e-3b7a-47d4-ba9a-311c22156933",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"y interecept:\")\n",
        "print(model.intercept_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y interecept:\n",
            "22.19738813257551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jliZ5bqacmwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# baseline sales number is the y-intercept, 22.19738813257551.\n",
        "# whenever every variable value is 0, there are 22.19738813257551 bars sold.  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}